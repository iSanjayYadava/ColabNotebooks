{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "004a_discriminative_lr.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iSanjayYadava/ColabNotebooks/blob/master/004a_discriminative_lr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "FULM3Q67fMOp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ddg9JDc6fVae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "98517afd-dfab-4c95-f739-507b82c6e739"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxXVOmoffMOv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#export\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/ColabNotebooks/')\n",
        "from nb_004 import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qGxfXeaxwTVh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The map() function applies a given function to each item of an iterable (list, tuple etc.) and returns a list of the results.\n"
      ]
    },
    {
      "metadata": {
        "id": "owfGS0VAfMOz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATA_PATH = Path('/content/gdrive/My Drive/ColabNotebooks/data')\n",
        "PATH = DATA_PATH/'cifar10_dog_air'\n",
        "#PATH = DATA_PATH/'cifar10'\n",
        "\n",
        "data_mean,data_std = map(tensor, ([0.491, 0.482, 0.447], [0.247, 0.243, 0.261]))\n",
        "cifar_norm,cifar_denorm = normalize_funcs(data_mean,data_std)\n",
        "\n",
        "train_tfms = [flip_lr(p=0.5),\n",
        "              pad(padding=4),\n",
        "              crop(size=32, row_pct=(0,1.), col_pct=(0,1.))]\n",
        "valid_tfms = []\n",
        "\n",
        "bs = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cTVFGHs4fMO2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tweaks to the OptimWrapper to handle an array of lrs/wds/..."
      ]
    },
    {
      "metadata": {
        "id": "ydEHG1pBfMO3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will modify OptimWrapper so that it accepts lists of hyperparameters (learning rate, weight decay, momentum, beta, alpha). We will use this by first defining a set of groups of layers and then defining one hyperparameter value for each group.\n",
        "\n",
        "An example of this is _Discriminative learning rates_, which consists of using different learning rates on different layers during training."
      ]
    },
    {
      "metadata": {
        "id": "NkOtWod1w5z3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The **filter()** method filters the given sequence with the help of a function \n",
        "that tests each element in the sequence to be true or not.\n",
        "returns an iterator that is already filtered."
      ]
    },
    {
      "metadata": {
        "id": "wpifRmz4xj8J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**torch.nn.Module**: \n",
        "\tBase class for all neural network modules.\n",
        "\tYour models should also subclass this class.\n",
        "  \n",
        "**torch.nn.Module.parameters**:\n",
        "\tReturns an iterator over module parameters."
      ]
    },
    {
      "metadata": {
        "id": "uyndjqE9ytW9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**torch.optim** is a package implementing various optimization algorithms.\n",
        "To use **torch.optim** you have to construct an optimizer object, \n",
        "that will hold the current state and will update the parameters based on the computed gradients.\n",
        "\n",
        "To construct an Optimizer you have to give it an iterable containing the parameters\n",
        "(all should be Variable s) to optimize. Then, you can specify optimizer-specific\n",
        "options such as the learning rate, weight decay, etc.\n",
        "\n",
        "Example:\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9)\n",
        "optimizer = optim.Adam([var1, var2], lr = 0.0001)\n",
        "\n",
        "\n",
        "Optimizers also support specifying per-parameter options. To do this, \n",
        "instead of passing an iterable of Variables, pass in an iterable of dict s. \n",
        "Each of them will define a separate parameter group, and should contain a params key, \n",
        "containing a list of parameters belonging to it. Other keys should match the keyword \n",
        "arguments accepted by the optimizers, and will be used as optimization options for this group.\n",
        "\n",
        "**optim.SGD**([\n",
        "\n",
        "                {'params': model.base.parameters()},\n",
        "                {'params': model.classifier.parameters(), 'lr': 1e-3}\n",
        "          ], lr=1e-2, momentum=0.9)"
      ]
    },
    {
      "metadata": {
        "id": "Rz4saoyy0Ho_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "torch.optim.Optimizer(params, defaults):Base class for all optimizers.\n",
        "\n",
        "**Parameters**:\t\n",
        "\n",
        "    params (iterable) – an iterable of torch.Tensor s or dict s. Specifies what Tensors should be optimized.\n",
        "    defaults – (dict): a dict containing default values of optimization options (used when a parameter group doesn’t specify them)\n",
        "\n",
        "**add_param_group**(param_group)\n",
        "\tAdd a param group to the Optimizer s param_groups.\n",
        "\tThis can be useful when fine tuning a pre-trained network as frozen layers can be made trainable and added to the Optimizer as training progresses.\n",
        "\n",
        "**load_state_dict**(state_dict)\n",
        "    Loads the optimizer state.\n",
        "    Parameters:\tstate_dict (dict) – optimizer state. Should be an object returned from a call to state_dict().\n",
        "\n",
        "**state_dict**()\n",
        "    Returns the state of the optimizer as a dict.\n",
        "    It contains two entries:\n",
        "        state - a dict holding current optimization state. Its content differs between optimizer classes.\n",
        "\n",
        "        param_groups - a dict containing all parameter groups\n",
        "\n",
        "**zero_grad**()\n",
        "    Clears the gradients of all optimized torch.Tensor s."
      ]
    },
    {
      "metadata": {
        "id": "6sJ65jIvfMO4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#export\n",
        "ModuleList = Collection[nn.Module]\n",
        "ParamList = Collection[nn.Parameter]\n",
        "\n",
        "bn_types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)\n",
        "\n",
        "def requires_grad(l:nn.Module, b:Optional[bool]=None)->Optional[bool]:\n",
        "    \"If b is not set requires_grad on all params in l, else return requires_grad of first param\"\n",
        "    ps = list(l.parameters())\n",
        "    if not ps: return None\n",
        "    if b is None: return ps[0].requires_grad\n",
        "    for p in ps: p.requires_grad=b\n",
        "\n",
        "def trainable_params(m:nn.Module)->ParamList: \n",
        "    \"Return list of trainable params in `m`\"\n",
        "    res = filter(lambda p: p.requires_grad, m.parameters())\n",
        "    return res\n",
        "\n",
        "def split_bn_bias(layer_groups:ModuleList)->ModuleList:\n",
        "    \"Sort each layer in  `layer_groups` into batchnorm (`bn_types`) and non-batchnorm groups\"\n",
        "    split_groups = []\n",
        "    for l in layer_groups:\n",
        "        l1,l2 = [],[]\n",
        "        for c in l.children():\n",
        "            if isinstance(c, bn_types): l2.append(c)\n",
        "            else:                       l1.append(c)\n",
        "        split_groups += [nn.Sequential(*l1), nn.Sequential(*l2)]\n",
        "    return split_groups"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6B9CtJ7mfMO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d68b6a34-3a54-4703-9468-2858a97c0245"
      },
      "cell_type": "code",
      "source": [
        "type(optim.SGD)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "type"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "cLHRpTUbfMO_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#export\n",
        "class OptimWrapper():\n",
        "    \"Basic wrapper around an optimizer to simplify HP changes\"\n",
        "    def __init__(self, opt:optim.Optimizer, wd:Floats=0., true_wd:bool=False, bn_wd:bool=True)->None:\n",
        "        self.opt,self.true_wd,self.bn_wd = opt,true_wd,bn_wd\n",
        "        self.opt_keys = list(self.opt.param_groups[0].keys())\n",
        "        self.opt_keys.remove('params')\n",
        "        self.read_defaults()\n",
        "        self.wd = wd\n",
        "        \n",
        "    @classmethod\n",
        "    def create(cls, opt_fn:Union[type,Callable], lr:Union[float,Tuple,List], \n",
        "               layer_groups:ModuleList, **kwargs:Any)->optim.Optimizer:\n",
        "        \"Create an optim.Optimizer from `opt_fn` with `lr`. Set lr on `layer_groups``\"\n",
        "        split_groups = split_bn_bias(layer_groups)\n",
        "        opt = opt_fn([{'params': trainable_params(l), 'lr':0} for l in split_groups])\n",
        "        opt = cls(opt, **kwargs)\n",
        "        opt.lr = listify(lr, layer_groups)\n",
        "        return opt\n",
        "    \n",
        "    def __repr__(self)->str:\n",
        "        return f'OptimWrapper over {repr(self.opt)}.\\nTrue weight decay: {self.true_wd}'\n",
        "\n",
        "    #Pytorch optimizer methods\n",
        "    def step(self)->None:\n",
        "        \"Set weight decay and step optimizer\"\n",
        "        # weight decay outside of optimizer step (AdamW)\n",
        "        if self.true_wd:\n",
        "            for lr,wd,pg1,pg2 in zip(self._lr,self._wd,self.opt.param_groups[::2],self.opt.param_groups[1::2]):\n",
        "                for p in pg1['params']: p.data.mul_(1 - wd*lr)\n",
        "                if self.bn_wd:\n",
        "                    for p in pg2['params']: p.data.mul_(1 - wd*lr)\n",
        "            self.set_val('weight_decay', listify(0, self._wd))\n",
        "        self.opt.step()\n",
        "    \n",
        "    def zero_grad(self)->None: \n",
        "        \"Clear optimizer gradients\"\n",
        "        self.opt.zero_grad()\n",
        "    \n",
        "    #Hyperparameters as properties\n",
        "    @property\n",
        "    def lr(self)->float: \n",
        "        \"Get learning rate\"\n",
        "        return self._lr[-1]\n",
        "\n",
        "    @lr.setter\n",
        "    def lr(self, val:float)->None: \n",
        "        \"Set learning rate\"\n",
        "        self._lr = self.set_val('lr', listify(val, self._lr))\n",
        "    \n",
        "    @property\n",
        "    def mom(self)->float: \n",
        "        \"Get momentum\"\n",
        "        return self._mom[-1]\n",
        "\n",
        "    @mom.setter\n",
        "    def mom(self, val:float)->None:\n",
        "        \"Set momentum\"\n",
        "        if 'momentum' in self.opt_keys: self.set_val('momentum', listify(val, self._mom))\n",
        "        elif 'betas' in self.opt_keys:  self.set_val('betas', (listify(val, self._mom), self._beta))\n",
        "        self._mom = listify(val, self._mom)\n",
        "    \n",
        "    @property\n",
        "    def beta(self)->float: \n",
        "        \"get beta\"\n",
        "        return None if self._beta is None else self._beta[-1]\n",
        "\n",
        "    @beta.setter\n",
        "    def beta(self, val:float)->None:\n",
        "        \"Set beta (or alpha as makes sense for give optimizer)\"\n",
        "        if val is None: return\n",
        "        if 'betas' in self.opt_keys:    self.set_val('betas', (self._mom, listify(val, self._beta)))\n",
        "        elif 'alpha' in self.opt_keys:  self.set_val('alpha', listify(val, self._beta))\n",
        "        self._beta = listify(val, self._beta)\n",
        "    \n",
        "    @property\n",
        "    def wd(self)->float: \n",
        "        \"Get weight decay\"\n",
        "        return self._wd[-1]\n",
        "\n",
        "    @wd.setter\n",
        "    def wd(self, val:float)->None:\n",
        "        \"Set weight decay\"\n",
        "        if not self.true_wd: self.set_val('weight_decay', listify(val, self._wd), bn_groups=self.bn_wd)\n",
        "        self._wd = listify(val, self._wd)\n",
        "    \n",
        "    #Helper functions\n",
        "    def read_defaults(self)->None:\n",
        "        \"Read the values inside the optimizer for the hyper-parameters\"\n",
        "        self._beta = None\n",
        "        if 'lr' in self.opt_keys: self._lr = self.read_val('lr')\n",
        "        if 'momentum' in self.opt_keys: self._mom = self.read_val('momentum')\n",
        "        if 'alpha' in self.opt_keys: self._beta = self.read_val('alpha')\n",
        "        if 'betas' in self.opt_keys: self._mom,self._beta = self.read_val('betas')\n",
        "        if 'weight_decay' in self.opt_keys: self._wd = self.read_val('weight_decay')\n",
        "    \n",
        "    def set_val(self, key:str, val:Any, bn_groups:bool=True)->Any:\n",
        "        \"Set the values inside the optimizer dictionary at the key\"\n",
        "        if is_tuple(val): val = [(v1,v2) for v1,v2 in zip(*val)]\n",
        "        for v,pg1,pg2 in zip(val,self.opt.param_groups[::2],self.opt.param_groups[1::2]): \n",
        "            pg1[key] = v\n",
        "            if bn_groups: pg2[key] = v\n",
        "        return val\n",
        "    \n",
        "    def read_val(self, key:str) -> Union[List[float],Tuple[List[float],List[float]]]:\n",
        "        \"Read a hyper-parameter key in the optimizer dictionary.\"\n",
        "        val = [pg[key] for pg in self.opt.param_groups[::2]]\n",
        "        if is_tuple(val[0]): val = [o[0] for o in val], [o[1] for o in val]\n",
        "        return val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PSyX5SaGfMPC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#export\n",
        "def children(m:nn.Module)->ModuleList: \n",
        "    \"Get children of module\"\n",
        "    return list(m.children())\n",
        "def num_children(m:nn.Module)->int: \n",
        "    \"Get number of child modules in module\"\n",
        "    return len(children(m))\n",
        "def range_children(m:nn.Module)->Iterator[int]: \n",
        "    \"Return iterator of len of children of m\"\n",
        "    return range(num_children(m))\n",
        "\n",
        "flatten_model=lambda l: sum(map(flatten_model,l.children()),[]) if num_children(l) else [l]\n",
        "def first_layer(m:nn.Module)->nn.Module:\n",
        "    \"Retrieve first layer in a module\"\n",
        "    return flatten_model(m)[0]\n",
        "\n",
        "def split_model_idx(model:nn.Module, idxs:Collection[int])->ModuleList:\n",
        "    \"Split the model according to the indices in [idxs]\"\n",
        "    layers = flatten_model(model)\n",
        "    if idxs[0] != 0: idxs = [0] + idxs\n",
        "    if idxs[-1] != len(layers): idxs.append(len(layers))\n",
        "    return [nn.Sequential(*layers[i:j]) for i,j in zip(idxs[:-1],idxs[1:])]\n",
        "\n",
        "def split_model(model:nn.Module, splits:Collection[ModuleList], want_idxs:bool=False):\n",
        "    \"Split the model according to the layers in [splits]\"\n",
        "    layers = flatten_model(model)\n",
        "    idxs = [layers.index(first_layer(s)) for s in listify(splits)]\n",
        "    res = split_model_idx(model, idxs)\n",
        "    return (res,idxs) if want_idxs else res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a4vBRtP9fMPH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will now try our Wrapper with the Darknet neural net architecture."
      ]
    },
    {
      "metadata": {
        "id": "U1jn6VA1fMPJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Darknet([1, 2, 2, 2, 2], num_classes=2, nf=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YJ0JvkE_fMPR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We are now going to split the model in layers so that we can try our OptimWrapper with more than one value per hyperparameter. In particular, we are going to split the 18 layers in the model into three groups: 0-5, 6-9 and 10-18. Afterwards, when setting the value for our hyperparameters, we will need to define a different value for each of these groups."
      ]
    },
    {
      "metadata": {
        "id": "yaBh1BtwfMPT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d93029fc-7e2b-4de5-9b0a-e4632ad1ee3c"
      },
      "cell_type": "code",
      "source": [
        "splits = [model.layers[9], model.layers[15]]\n",
        "layer_groups,idxs = split_model(model, splits, want_idxs=True)\n",
        "lrs = np.array([1e-3,1e-2,0.1])\n",
        "tst_opt = OptimWrapper.create(optim.SGD, lrs, layer_groups, bn_wd=False)\n",
        "idxs"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[42, 72]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "1_h9vytLfMPV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e6fa508-2d7a-4e43-e82e-21bed563f470"
      },
      "cell_type": "code",
      "source": [
        "len(tst_opt.opt.param_groups), tst_opt.opt.param_groups[0]['weight_decay']"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "h4yXgucAfMPY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d281eb9-6e00-4dd8-ae79-530f78df16cd"
      },
      "cell_type": "code",
      "source": [
        "tst_opt.opt.param_groups[0]['lr'],tst_opt.opt.param_groups[1]['lr']"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.001, 0.001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "CbJ1EVUFfMPa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tst_opt.wd = 1e-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-wceO2EJfMPd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74bb9b3b-e91b-426c-fdc0-63a43145056f"
      },
      "cell_type": "code",
      "source": [
        "tst_opt.opt.param_groups[0]['weight_decay'],tst_opt.opt.param_groups[1]['weight_decay']"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.01, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "4cQPyn7yfMPg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tst_opt.lr = 1e-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZCKmLtY7fMPj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37d50563-ffd3-4e66-a072-19e8854e015d"
      },
      "cell_type": "code",
      "source": [
        "tst_opt.opt.param_groups[0]['lr'],tst_opt.opt.param_groups[1]['lr']"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.01, 0.01)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "dWubOgRgfMPl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can set the hyperparameters in two ways:\n",
        "\n",
        "1. optimizer_object.\\_hyperparameter = [val1, val2 ..., valn] (n = number of layer groups)\n",
        "\n",
        "2. optimizer_object.hyperparameter = val\n",
        "\n",
        "If we chose to set it in way 1, we must specify a number of values exactly equal to the number of layer groups. If we chose to set it in way 2, the chosen value will be repeated for all layer groups."
      ]
    },
    {
      "metadata": {
        "id": "Kpu8iujwfMPm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ee05aca-1175-4864-e1cf-0ac8bba9a8db"
      },
      "cell_type": "code",
      "source": [
        "tst_opt.lr, tst_opt._lr"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.01, [0.01, 0.01, 0.01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "l02pOMFBfMPq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d02cb654-a7f9-4e43-fdab-5a778cf8b07e"
      },
      "cell_type": "code",
      "source": [
        "tst_opt.wd, tst_opt._wd"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.01, [0.01, 0.01, 0.01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "P0IV3aqJfMPx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# expect exception\n",
        "# tst_opt.wd = [0.1,0.1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YGyjIi3-fMP2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# expect exception\n",
        "# tst_opt.lr = [0.1,0.1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EPU69-THfMP4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Now let's tweak the learner to handle this."
      ]
    },
    {
      "metadata": {
        "id": "1IyGRtqTfMP5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have added some important functions into the Learner class. We have built *create_opt* that creates the optimizer with the wrapper, _split_ that splits our model into layer groups, *freeze_to*, _freeze_ and _unfreeze_ that allow us to freeze and unfreeze parts of the network or even the whole network.\n",
        "\n",
        "Add gradient clipping at this stage in a callback."
      ]
    },
    {
      "metadata": {
        "id": "gFdAoDl3fMP6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#export\n",
        "bn_types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)\n",
        "\n",
        "def set_bn_eval(m:nn.Module)->None:\n",
        "    \"Set bn layers in eval mode for all recursive children of m\"\n",
        "    for l in m.children():\n",
        "        if isinstance(l, bn_types) and not next(l.parameters()).requires_grad:\n",
        "            l.eval()\n",
        "        set_bn_eval(l)\n",
        "\n",
        "@dataclass\n",
        "class BnFreeze(Callback):\n",
        "    \"Set all bntypes layers in `learn` to eval() on_epoch_begin\"\n",
        "    learn:Learner\n",
        "    def on_epoch_begin(self, **kwargs:Any)->None: \n",
        "        \"Put bn layers in eval mode on epoch_begin\"\n",
        "        set_bn_eval(self.learn.model)\n",
        "\n",
        "def even_mults(start:float, stop:float, n:int)->np.ndarray:\n",
        "    \"Build evenly stepped schedule from start to stop in n steps\"\n",
        "    mult = stop/start\n",
        "    step = mult**(1/(n-1))\n",
        "    return np.array([start*(step**i) for i in range(n)])\n",
        "\n",
        "default_lr = slice(3e-3)\n",
        "default_wd = 1e-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-8PXjj_zfMP9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#export\n",
        "\n",
        "SplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\n",
        "@dataclass\n",
        "class Learner():\n",
        "    \"Object that wraps together some data, a model, a loss function and an optimizer\"\n",
        "    data:DataBunch\n",
        "    model:nn.Module\n",
        "    opt_fn:Callable=AdamW\n",
        "    loss_fn:Callable=F.cross_entropy\n",
        "    metrics:Collection[Callable]=None\n",
        "    true_wd:bool=True\n",
        "    bn_wd:bool=True\n",
        "    wd:Floats=default_wd\n",
        "    train_bn:bool=True\n",
        "    path:str = None\n",
        "    model_dir:str = 'models'\n",
        "    callback_fns:Collection[Callable]=None\n",
        "    callbacks:Collection[Callback]=field(default_factory=list)\n",
        "    layer_groups:Collection[nn.Module]=None\n",
        "    def __post_init__(self)->None:\n",
        "        \"Setup path,metrics, callbacks and ensure model directory exists\"\n",
        "        self.path = Path(ifnone(self.path, self.data.path))\n",
        "        (self.path/self.model_dir).mkdir(parents=True, exist_ok=True)\n",
        "        self.model = self.model.to(self.data.device)\n",
        "        self.metrics=listify(self.metrics)\n",
        "        if not self.layer_groups: self.layer_groups = [nn.Sequential(*flatten_model(self.model))]\n",
        "        self.callbacks = listify(self.callbacks)\n",
        "        self.callback_fns = [Recorder] + listify(self.callback_fns)\n",
        "\n",
        "    def lr_range(self, lr:Union[float,slice])->np.ndarray:\n",
        "        \"Build learning rate schedule\"\n",
        "        if not isinstance(lr,slice): return lr\n",
        "        if lr.start: res = even_mults(lr.start, lr.stop, len(self.layer_groups))\n",
        "        else: res = [lr.stop/3]*(len(self.layer_groups)-1) + [lr.stop]\n",
        "        return np.array(res)\n",
        "        \n",
        "    def fit(self, epochs:int, lr:Union[Floats,slice]=default_lr, \n",
        "            wd:Floats=None, callbacks:Collection[Callback]=None)->None:\n",
        "        \"fit the model on this learner with `lr` learning rate, `wd` weight decay for `epochs` with `callbacks`\"\n",
        "        lr = self.lr_range(lr)\n",
        "        if wd is None: wd = self.wd\n",
        "        self.create_opt(lr, wd)\n",
        "        callbacks = [cb(self) for cb in self.callback_fns] + listify(callbacks)\n",
        "        fit(epochs, self.model, self.loss_fn, opt=self.opt, data=self.data, metrics=self.metrics,\n",
        "            callbacks=self.callbacks+callbacks)\n",
        "\n",
        "    def create_opt(self, lr:Floats, wd:Floats=0.)->None:\n",
        "        \"create optimizer with `lr` learning rate and `wd` weight decay\"\n",
        "        self.opt = OptimWrapper.create(self.opt_fn, lr, self.layer_groups, wd=wd, true_wd=self.true_wd, bn_wd=self.bn_wd)\n",
        "        \n",
        "    def split(self, split_on:SplitFuncOrIdxList)->None:\n",
        "        \"split the model at `split_on`\"\n",
        "        if isinstance(split_on,Callable): self.layer_groups = split_on(self.model)\n",
        "        else: self.layer_groups = split_model(self.model, split_on)\n",
        "\n",
        "    def freeze_to(self, n:int)->None:\n",
        "        \"freeze layers up to layer `n`\"\n",
        "        for g in self.layer_groups[:n]:\n",
        "            for l in g:\n",
        "                if not self.train_bn or not isinstance(l, bn_types): requires_grad(l, False)\n",
        "        for g in self.layer_groups[n:]: requires_grad(g, True)\n",
        "\n",
        "    def freeze(self)->None:\n",
        "        \"freeze up to last layer\"\n",
        "        assert(len(self.layer_groups)>1)\n",
        "        self.freeze_to(-1)\n",
        "        \n",
        "    def unfreeze(self): \n",
        "        \"unfreeze entire model\"\n",
        "        self.freeze_to(0)\n",
        "    def __del__(self): del(self.model, self.data)        \n",
        "    def save(self, name:PathOrStr): \n",
        "        \"save model with `name` to `self.model_dir`\"\n",
        "        torch.save(self.model.state_dict(), self.path/self.model_dir/f'{name}.pth')\n",
        "    def load(self, name:PathOrStr): \n",
        "        \"load model `name` from `self.model_dir\"\n",
        "        self.model.load_state_dict(torch.load(self.path/self.model_dir/f'{name}.pth'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QvtRA407fMQC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#export\n",
        "def fit_one_cycle(learn:Learner, cyc_len:int,\n",
        "                  max_lr:Union[Floats,slice]=default_lr, moms:Tuple[float,float]=(0.95,0.85),\n",
        "                  div_factor:float=25., pct_start:float=0.3, wd:float=None, **kwargs)->None:\n",
        "    \"Fits a model following the 1cycle policy\"\n",
        "    max_lr = learn.lr_range(max_lr)\n",
        "    cbs = [OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor,\n",
        "                             pct_start=pct_start, **kwargs)]\n",
        "    learn.fit(cyc_len, max_lr, wd=wd, callbacks=cbs)\n",
        "\n",
        "Learner.fit_one_cycle = fit_one_cycle\n",
        "Learner.lr_find = lr_find"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GmG0YAXAfMQI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f314e692-eb62-43ae-8099-9daba6512d29"
      },
      "cell_type": "code",
      "source": [
        "train_ds = ImageDataset.from_folder(PATH/'train', classes=['airplane','dog'])\n",
        "valid_ds = ImageDataset.from_folder(PATH/'test', classes=['airplane','dog'])\n",
        "data = DataBunch.create(train_ds, valid_ds, bs=bs, train_tfm=train_tfms, valid_tfm=valid_tfms, dl_tfms=cifar_norm)\n",
        "len(data.train_dl), len(data.valid_dl)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "_ehr0fcmfMQK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Darknet([1, 2, 2, 2, 2], num_classes=2, nf=16)\n",
        "learn = Learner(data, model, true_wd=True)\n",
        "learn.metrics = [accuracy]\n",
        "learn.split((model.layers[9],model.layers[15]))\n",
        "learn.freeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CPxvliDKfMQO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "444ac41f-f83d-4dbc-9cdf-0c963b3786af"
      },
      "cell_type": "code",
      "source": [
        "l1,l2 = model.layers[0],model.layers[-1]; l1,l2"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Sequential(\n",
              "   (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "   (2): LeakyReLU(negative_slope=0.1, inplace)\n",
              " ), Linear(in_features=512, out_features=2, bias=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "sZWm9UusfMQS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ada84cd-ef2c-4d03-8d16-b8d6bed992d7"
      },
      "cell_type": "code",
      "source": [
        "requires_grad(l1[0]),requires_grad(l1[1]),requires_grad(l2)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, True, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "x1DyWOU_fMQV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As we know, setting a hyperparameter to a list of length different from the number of layer groups will return an error."
      ]
    },
    {
      "metadata": {
        "id": "ohDqA3vXfMQW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# expect exception\n",
        "# learn.fit(1, [0.1,0.1], wd=1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5VZW4IPvfMQZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "5b8bffef-f541-48ab-d43a-47f9e6af06d4"
      },
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(1, slice(1e-1))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 32:38 <p>epoch  train loss  valid loss  accuracy<p>0      0.320104    0.285866    0.905128"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "n2q0h7WRfMQb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "b5376885-196d-4220-8f28-92eecc26393d"
      },
      "cell_type": "code",
      "source": [
        "learn.recorder.plot_lr()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFKCAYAAAAnj5dkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "148hhmyofMQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "166b205e-90b0-4cf4-ee69-6f20b086f0c2"
      },
      "cell_type": "code",
      "source": [
        "learn.fit(1, 1e-1, wd=1e-2)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 00:27 <p>epoch  train loss  valid loss  accuracy<p>0      0.375506    1.343470    0.464103"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Ya_3utg6fMQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c521d9d2-b27e-4738-ac11-036c159ed776"
      },
      "cell_type": "code",
      "source": [
        "learn.opt._lr"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1, 0.1, 0.1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "S5ApuIOMfMQk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "16dd2bf0-f03b-4458-ab7f-d68d6b39490f"
      },
      "cell_type": "code",
      "source": [
        "learn.fit(1, slice(1e-3,1e-1), wd=1e-2)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 00:27 <p>epoch  train loss  valid loss  accuracy<p>0      0.289606    0.411047    0.871795"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "vI_iwbTOfMQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c01ad5a-522d-462d-ae74-b886e808fb44"
      },
      "cell_type": "code",
      "source": [
        "learn.opt._lr"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.001, 0.01, 0.1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "-VRH7GmyfMQq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d1Yk68IBfMQs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c760344b-9def-4110-a86a-6615621cde6d"
      },
      "cell_type": "code",
      "source": [
        "requires_grad(l1[0]),requires_grad(l1[1]),requires_grad(l2)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "aXkX1cYPfMQu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "680964fc-86ce-41af-f8f5-9231a1977b1e"
      },
      "cell_type": "code",
      "source": [
        "learn.fit(1, lrs, wd=1e-2)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 00:27 <p>epoch  train loss  valid loss  accuracy<p>0      0.304221    0.407935    0.851282"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "OifLw1_VfMQx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Darknet([1, 2, 2, 2, 2], num_classes=2, nf=16)\n",
        "learn = Learner(data, model)\n",
        "learn.metrics = [accuracy]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5W7Zy3n3fMQ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "b6f89262-a4ff-4bbf-853b-3179e90d6d42"
      },
      "cell_type": "code",
      "source": [
        "learn.fit(1,0.1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 00:27 <p>epoch  train loss  valid loss  accuracy<p>0      0.548543    0.515250    0.876923"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "wcGCT4ESfMQ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab63cd69-cae1-454b-f4c5-91a6b3bd501b"
      },
      "cell_type": "code",
      "source": [
        "learn.opt._lr"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "iOBYQfytfMQ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def darknet_split(m) : return split_model(m,[m.layers[9],m.layers[15]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8SBY0d6pfMQ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Darknet([1, 2, 2, 2, 2], num_classes=2, nf=16)\n",
        "learn = Learner(data, model, metrics=[accuracy])\n",
        "learn.split(darknet_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tpz_UVAhfMRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b6961e2-58a2-4165-ba1b-e3dc2ec9adf3"
      },
      "cell_type": "code",
      "source": [
        "len(learn.layer_groups)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "5cNJeXbtfMRE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "479821a1-0c31-424a-e6c2-f40173622108"
      },
      "cell_type": "code",
      "source": [
        "learn.fit(1, lrs, wd=[1e-4,1e-3,1e-2])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 00:28 <p>epoch  train loss  valid loss  accuracy<p>0      0.492684    0.371107    0.838462"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Tt0tUOWyfMRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5352ad92-9a9b-4e50-88d3-1a36020d2fe1"
      },
      "cell_type": "code",
      "source": [
        "learn.opt._wd"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0001, 0.001, 0.01]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "iCYiIPVCfMRJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# exception expected\n",
        "# learn.fit(1, lrs, wd=[1e-4,1e-3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3vtc2D1bfMRL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "LRs and WDs are the easiest to pass through the Learner, but if a Callback sets an array of moms or betas, the OptimWrapper will handle them as discriminative moms/betas."
      ]
    },
    {
      "metadata": {
        "id": "3GGBh_kkfMRN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## See how it fits with the other callbacks"
      ]
    },
    {
      "metadata": {
        "id": "PohalTugfMRO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Darknet([1, 2, 2, 2, 2], num_classes=2, nf=16)\n",
        "learn = Learner(data, model, metrics = [accuracy])\n",
        "learn.split(darknet_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JX4szXDCfMRS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "8258dba7-e101-4965-b302-c542fe856bb0"
      },
      "cell_type": "code",
      "source": [
        "lr_find(learn, start_lr=lrs/1000, end_lr=lrs*100)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "epoch  train loss  valid loss  accuracy<p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='progress-bar-interrupted' max='129', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      Interrupted\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "TZGe9OP1fMRV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "692cd85e-3ba2-4a9b-ab1e-5d2f35e6d54a"
      },
      "cell_type": "code",
      "source": [
        "learn.recorder.plot()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFOCAYAAACxAKU1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "wjTbFIoFfMRX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "744d1b04-4830-4050-f731-e889c883ca26"
      },
      "cell_type": "code",
      "source": [
        "sched = OneCycleScheduler(learn, lrs)\n",
        "learn.fit(1, lrs, callbacks=[sched])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 00:28 <p>epoch  train loss  valid loss  accuracy<p>0      0.255261    0.213050    0.900000"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "01stcDp-fMRc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}